{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ✈️ Optimized Flight Route Finder with GNN & Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: torch in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torch-geometric in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.6.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.4.2)\n",
      "Requirement already satisfied: folium in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.19.5)\n",
      "Requirement already satisfied: haversine in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.9.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch-geometric) (3.11.16)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\ekaansh\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch-geometric) (3.2.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch-geometric) (4.67.1)\n",
      "Requirement already satisfied: branca>=0.6.0 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from folium) (0.8.1)\n",
      "Requirement already satisfied: xyzservices in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from folium) (2025.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->torch-geometric) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->torch-geometric) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->torch-geometric) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->torch-geometric) (6.3.2)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->torch-geometric) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from aiohttp->torch-geometric) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torch-geometric) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->torch-geometric) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\ekaansh\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas torch torch-geometric networkx folium haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import folium\n",
    "from haversine import haversine\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_df = pd.read_csv(\"normalized_airports.csv\")\n",
    "routes_df = pd.read_csv(\"https://raw.githubusercontent.com/jpatokal/openflights/master/data/routes.dat\", header=None)\n",
    "routes_df.columns = [\"Airline\", \"Airline ID\", \"Source Airport\", \"Source Airport ID\", \n",
    "                     \"Destination Airport\", \"Destination Airport ID\", \"Codeshare\", \n",
    "                     \"Stops\", \"Equipment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_to_idx = {code: i for i, code in enumerate(airports_df[\"IATA\"])}\n",
    "idx_to_airport = {i: code for code, i in airport_to_idx.items()}\n",
    "airport_to_city = dict(zip(airports_df[\"IATA\"], airports_df[\"City\"]))\n",
    "airport_to_country = dict(zip(airports_df[\"IATA\"], airports_df[\"Country\"]))\n",
    "\n",
    "valid_routes = []\n",
    "for _, row in routes_df.iterrows():\n",
    "    src, dst = row[\"Source Airport\"], row[\"Destination Airport\"]\n",
    "    if src in airport_to_idx and dst in airport_to_idx:\n",
    "        src_info = airports_df[airports_df[\"IATA\"] == src].iloc[0]\n",
    "        dst_info = airports_df[airports_df[\"IATA\"] == dst].iloc[0]\n",
    "        dist = haversine((src_info[\"Latitude\"], src_info[\"Longitude\"]),\n",
    "                         (dst_info[\"Latitude\"], dst_info[\"Longitude\"]))\n",
    "        valid_routes.append((airport_to_idx[src], airport_to_idx[dst], dist, row[\"Airline\"]))\n",
    "\n",
    "G = nx.DiGraph()\n",
    "for src, dst, weight, airline in valid_routes:\n",
    "    G.add_edge(src, dst, weight=weight, airline=airline)\n",
    "\n",
    "edge_index = torch.tensor([[src, dst] for src, dst, _, _ in valid_routes], dtype=torch.long).T\n",
    "x = torch.tensor(airports_df[[\"Latitude\", \"Longitude\", \"Altitude\"]].values, dtype=torch.float)\n",
    "data = Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 1.7723\n",
      "Epoch 10, Loss: 1.0977\n",
      "Epoch 20, Loss: 0.7267\n",
      "Epoch 30, Loss: 0.5034\n",
      "Epoch 40, Loss: 0.3629\n",
      "Epoch 50, Loss: 0.3040\n",
      "Epoch 60, Loss: 0.2793\n",
      "Epoch 70, Loss: 0.2564\n",
      "Epoch 80, Loss: 0.2362\n",
      "Epoch 90, Loss: 0.2177\n"
     ]
    }
   ],
   "source": [
    "class FlightRouteGNN(torch.nn.Module):\n",
    "    def __init__(self, input_dim=3, hidden_dim=8):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, input_dim)  # match output to input dim\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = FlightRouteGNN(input_dim=3, hidden_dim=8)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = torch.nn.functional.mse_loss(out, data.x)  # Autoencoder reconstruction\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_route(src_iata, dst_iata, max_hops=5, allowed_airlines=None, max_layover=15000):\n",
    "    src = airport_to_idx.get(src_iata)\n",
    "    dst = airport_to_idx.get(dst_iata)\n",
    "    if src is None or dst is None:\n",
    "        return \"Invalid airport codes\", []\n",
    "\n",
    "    node_embeddings = model(data).detach().numpy()\n",
    "    for u, v in G.edges():\n",
    "        gnn_dist = torch.norm(torch.tensor(node_embeddings[u]) - torch.tensor(node_embeddings[v])).item()\n",
    "        base_weight = G[u][v]['weight']\n",
    "        G[u][v]['adjusted_weight'] = base_weight + gnn_dist * 0.3\n",
    "\n",
    "    try:\n",
    "        length, path = nx.single_source_dijkstra(G, src, target=dst, weight='adjusted_weight')\n",
    "        hops = len(path) - 1\n",
    "        if hops > max_hops:\n",
    "            return \"Too many hops\", []\n",
    "\n",
    "        filtered = []\n",
    "        valid = True\n",
    "        for u, v in zip(path[:-1], path[1:]):\n",
    "            edge = G.get_edge_data(u, v)\n",
    "            if allowed_airlines and edge[\"airline\"] not in allowed_airlines:\n",
    "                valid = False\n",
    "                break\n",
    "            if edge[\"weight\"] > max_layover:\n",
    "                valid = False\n",
    "                break\n",
    "            filtered.append((idx_to_airport[u], idx_to_airport[v], edge[\"airline\"], edge[\"weight\"]))\n",
    "\n",
    "        return None if valid else \"Route doesn't meet filter conditions\", filtered if valid else []\n",
    "    except nx.NetworkXNoPath:\n",
    "        return \"No path found\", []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_route_on_map(route):\n",
    "    m = folium.Map(location=[20, 0], zoom_start=2)\n",
    "    for u, v, airline, dist in route:\n",
    "        src = airports_df[airports_df[\"IATA\"] == u].iloc[0]\n",
    "        dst = airports_df[airports_df[\"IATA\"] == v].iloc[0]\n",
    "        folium.Marker(location=[src[\"Latitude\"], src[\"Longitude\"]], popup=f\"{u} ({src['City']})\").add_to(m)\n",
    "        folium.Marker(location=[dst[\"Latitude\"], dst[\"Longitude\"]], popup=f\"{v} ({dst['City']})\").add_to(m)\n",
    "        folium.PolyLine(\n",
    "            [(src[\"Latitude\"], src[\"Longitude\"]), (dst[\"Latitude\"], dst[\"Longitude\"])],\n",
    "            tooltip=f\"{airline} | {dist:.2f} km\",\n",
    "            color=\"blue\",\n",
    "        ).add_to(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "error, route = get_best_route(\"RPR\", \"LAX\", max_hops=5, allowed_airlines=None, max_layover=12000)\n",
    "if error:\n",
    "    print(\"Error:\", error)\n",
    "else:\n",
    "    m = plot_route_on_map(route)\n",
    "    m.save(\"route_map.html\")\n",
    "    m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6e91b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from haversine import haversine\n",
    "import folium\n",
    "from folium import PolyLine\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e834150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "airports_df = pd.read_csv(\"normalized_airports.csv\")\n",
    "routes_df = pd.read_csv(\"https://raw.githubusercontent.com/jpatokal/openflights/master/data/routes.dat\", header=None)\n",
    "routes_df.columns = [\"Airline\", \"Airline ID\", \"Source Airport\", \"Source Airport ID\", \n",
    "                     \"Destination Airport\", \"Destination Airport ID\", \"Codeshare\", \n",
    "                     \"Stops\", \"Equipment\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4195ac1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "airport_to_idx = {code: i for i, code in enumerate(airports_df[\"IATA\"])}\n",
    "idx_to_airport = {v: k for k, v in airport_to_idx.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25d97ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_routes = []\n",
    "for _, row in routes_df.iterrows():\n",
    "    src, dst = row[\"Source Airport\"], row[\"Destination Airport\"]\n",
    "    if src in airport_to_idx and dst in airport_to_idx:\n",
    "        src_info = airports_df[airports_df[\"IATA\"] == src].iloc[0]\n",
    "        dst_info = airports_df[airports_df[\"IATA\"] == dst].iloc[0]\n",
    "        distance = haversine((src_info[\"Latitude\"], src_info[\"Longitude\"]),\n",
    "                             (dst_info[\"Latitude\"], dst_info[\"Longitude\"]))\n",
    "        valid_routes.append((airport_to_idx[src], airport_to_idx[dst], distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6ba0598",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()\n",
    "for src, dst, weight in valid_routes:\n",
    "    G.add_edge(src, dst, weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "009b48e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data(\n",
    "    x=torch.tensor(airports_df[[\"Latitude\", \"Longitude\", \"Altitude\"]].values, dtype=torch.float),\n",
    "    edge_index=torch.tensor([[src, dst] for src, dst, _ in valid_routes], dtype=torch.long).T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58f5f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, out_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model = GCN(3, 16, 8)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "409b7818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ekaansh\\AppData\\Local\\Temp\\ipykernel_25472\\3894244832.py:5: UserWarning: Using a target size (torch.Size([7345, 3])) that is different to the input size (torch.Size([7345, 8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  loss = torch.nn.functional.mse_loss(out, data.x)  # Autoencoder style\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (8) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m optimizer.zero_grad()\n\u001b[32m      4\u001b[39m out = model(data)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m loss = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmse_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Autoencoder style\u001b[39;00m\n\u001b[32m      6\u001b[39m loss.backward()\n\u001b[32m      7\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ekaansh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\functional.py:3884\u001b[39m, in \u001b[36mmse_loss\u001b[39m\u001b[34m(input, target, size_average, reduce, reduction, weight)\u001b[39m\n\u001b[32m   3881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3882\u001b[39m     reduction = _Reduction.legacy_get_string(size_average, reduce)\n\u001b[32m-> \u001b[39m\u001b[32m3884\u001b[39m expanded_input, expanded_target = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3886\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3887\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m weight.size() != \u001b[38;5;28minput\u001b[39m.size():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Ekaansh\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\functional.py:76\u001b[39m, in \u001b[36mbroadcast_tensors\u001b[39m\u001b[34m(*tensors)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(tensors):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, *tensors)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbroadcast_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (8) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = torch.nn.functional.mse_loss(out, data.x)  # Autoencoder style\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc490aa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
